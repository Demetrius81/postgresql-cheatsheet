## 1. Оптимизация схемы и типов данных

**Что делать (SQL):**

* Правильные типы: `integer`/`bigint` вместо `text` для чисел, `jsonb` для JSON.
* Ограничения: `NOT NULL`, `CHECK`, `UNIQUE`, `FOREIGN KEY`.

```sql
ALTER TABLE orders
  ALTER COLUMN user_id TYPE bigint USING user_id::bigint,
  ALTER COLUMN status SET NOT NULL;
  
CREATE TABLE order_items (
  id BIGSERIAL PRIMARY KEY,
  order_id BIGINT NOT NULL REFERENCES orders(id),
  product_id BIGINT NOT NULL,
  quantity INT NOT NULL CHECK (quantity > 0)
);
```

**Как в Go (миграции):**

* Используйте миграции (migrate, goose, golang-migrate).
* Пример использования `golang-migrate` (shell в CI):

```bash
migrate -path ./migrations -database "$DATABASE_URL" up
```

**Генерация миграции (пример файла 001_create_orders.sql):**

```sql
-- +migrate Up
CREATE TABLE orders (
  id BIGSERIAL PRIMARY KEY,
  user_id BIGINT NOT NULL,
  status TEXT NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now()
);
-- +migrate Down
DROP TABLE orders;
```

---

## 2. Индексация

**SQL (создание индекса):**

```sql
CREATE INDEX idx_orders_user_status ON orders(user_id, status);
CREATE INDEX idx_orders_created_at ON orders(created_at DESC);
-- GIN для JSONB
CREATE INDEX idx_orders_meta ON orders USING GIN (meta jsonb_path_ops);
```

**Partial index (экономия места):**

```sql
CREATE INDEX idx_active_orders ON orders (user_id) WHERE status = 'active';
```

**Вызов из Go (однократная проверка/маиграция):**

```go
db.Exec(context.Background(), "CREATE INDEX IF NOT EXISTS idx_orders_user_status ON orders(user_id, status);")
```

---

## 3. Анализ медленных запросов (`EXPLAIN ANALYZE`)

**Как получить план в коде и логах:**

```sql
EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON)
SELECT o.id, o.status FROM orders o WHERE o.user_id = $1 ORDER BY o.created_at DESC LIMIT 10;
```

**Go (получение плана и логирование для slow queries):**

```go
func explainQuery(ctx context.Context, db *sql.DB, q string, args ...interface{}) (string, error) {
    row := db.QueryRowContext(ctx, "EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) " + q, args...)
    var plan string
    if err := row.Scan(&plan); err != nil {
        return "", err
    }
    return plan, nil
}
```

В production: ловите медленные запросы (логирование со стороны PostgreSQL или `pg_stat_statements`) и затем запускайте `EXPLAIN ANALYZE` локально/в staging.

---

## 4. Настройка памяти и кэша (параметры Postgres)

Эти параметры обычно в `postgresql.conf` (на сервере), но вы можете проверять/устанавливать некоторые через SQL (только для текущей сессии):

```sql
SHOW shared_buffers;
SET work_mem = '16MB';
```

**В Go (установка session-level параметров при подключении):**

```go
conn.Exec(ctx, "SET work_mem = '16MB'")
```

Для дев/CI: храните рекомендованные параметры в Ansible/Terraform/PG config management.

---

## 5. VACUUM / ANALYZE / autovacuum

**Вызов вручную:**

```sql
VACUUM (VERBOSE, ANALYZE) orders;
ANALYZE orders;
```

**Go (планировщик на стороне приложения или maintenance job):**

```go
func runMaintenance(ctx context.Context, db *sql.DB) error {
    _, err := db.ExecContext(ctx, "VACUUM (VERBOSE, ANALYZE) orders;")
    return err
}
```

**CI/ops:** настроить cron/pgAgent или управляющий инструмент, чтобы вызывать `VACUUM` регулярно; настроить разумный `autovacuum` в конфиге.

---

## 6. Партиционирование

**SQL (range partitioning по дате):**

```sql
CREATE TABLE orders_y2024 PARTITION OF orders
  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
```

**Создание партиционированной таблицы:**

```sql
CREATE TABLE orders (
  id BIGSERIAL,
  created_at TIMESTAMPTZ NOT NULL,
  ...
) PARTITION BY RANGE (created_at);
```

**Управление партициями в коде (автогенерация в миграциях):**

```go
// Пример создания партиции для месяца
db.Exec(ctx, `CREATE TABLE IF NOT EXISTS orders_2024_06 PARTITION OF orders
    FOR VALUES FROM ('2024-06-01') TO ('2024-07-01');`)
```

Партиционирование уменьшит объемы сканирования в больших таблицах.

---

## 7. Минимизация транзакций и bulk-операции

**Bulk insert через COPY (быстрее, чем INSERT):**

```sql
COPY orders (user_id, status, created_at) FROM STDIN WITH (FORMAT csv);
```

**Go (copy via pgx):**

```go
copyCount, err := pgxConn.CopyFrom(
    ctx,
    pgx.Identifier{"orders"},
    []string{"user_id", "status", "created_at"},
    pgx.CopyFromRows(rows), // rows [][]interface{}
)
```

**Batch update (пример):**

* Используйте `INSERT ... ON CONFLICT DO UPDATE` с batch или `UNLOGGED` временные таблицы + `UPDATE ... FROM temp_table`.

---

## 8. Устранение N+1 и использование предзагрузки

**ORM (GORM) preloading:**

```go
db.Preload("Items").Find(&orders)
```

**Raw SQL альтернативы (JOIN с ограничением):**

```sql
SELECT o.*, i.*
FROM orders o
LEFT JOIN order_items i ON i.order_id = o.id
WHERE o.user_id = $1;
```

**Однако** — иногда проще сначала получить list order ids, а затем второй запрос для items (меньше дублируемых данных).

---

## 9. Connection pool и настройки клиента

**Go (pgxpool example):**

```go
config, _ := pgxpool.ParseConfig(os.Getenv("DATABASE_URL"))
config.MaxConns = 50
config.MinConns = 5
config.HealthCheckPeriod = 30 * time.Second
pool, err := pgxpool.ConnectConfig(ctx, config)
```

**Советы:**

* Настройте `MaxConns` чтобы не перегружать Postgres (в связке с `max_connections`).
* Избегайте открытия/закрытия коннектов в каждом запросе.

---

## 10. Использование индексов для `ORDER BY` и `LIMIT`

Если часто делаете `ORDER BY created_at DESC LIMIT 10` — создайте индекс:

```sql
CREATE INDEX idx_orders_created_at_desc ON orders (created_at DESC);
```

Это даст `Index Only Scan` при покрывающем индексе.

---

## 11. Partial indexes и expression indexes

**Partial index:**

```sql
CREATE INDEX idx_orders_pending ON orders (user_id) WHERE status = 'pending';
```

**Expression index (lower-case search):**

```sql
CREATE INDEX idx_users_email_lower ON users (lower(email));
```

---

## 12. GIN индекс для `jsonb` и полнотекстового поиска

```sql
CREATE INDEX idx_orders_meta_gin ON orders USING GIN (meta jsonb_path_ops);
CREATE INDEX idx_docs_fts ON documents USING GIN (to_tsvector('russian', content));
```

---

## 13. Использование `pg_stat_statements` и мониторинг

**Включение (postgresql.conf):**

```
shared_preload_libraries = 'pg_stat_statements'
pg_stat_statements.max = 10000
pg_stat_statements.track = all
```

**Запрос топ медленных SQL:**

```sql
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY total_time DESC
LIMIT 10;
```

**В Go — собрать и отправить в лог/alert:**

```go
rows, _ := db.QueryContext(ctx, "SELECT query, calls, total_time FROM pg_stat_statements ORDER BY total_time DESC LIMIT 10")
```

---

## 14. Архитектурные паттерны: кэширование, очереди, materialized views

**Кэш (Redis) для «горячих» запросов:**

```go
val, err := redisClient.Get(ctx, cacheKey).Result()
if err == redis.Nil {
    // запросить из Postgres и Set с TTL
    dbVal := queryFromDB(...)
    redisClient.Set(ctx, cacheKey, dbVal, time.Minute*5)
}
```

**Materialized view для агрегатов:**

```sql
CREATE MATERIALIZED VIEW daily_order_counts AS
SELECT date_trunc('day', created_at) AS day, count(*) FROM orders GROUP BY day;
-- REFRESH MATERIALIZED VIEW daily_order_counts;
```

**Автоматическое обновление:** `REFRESH MATERIALIZED VIEW CONCURRENTLY` в off-peak.

**Queues (offload work):** используйте Kafka/Redis Streams/RabbitMQ для фоновых задач (например, heavy reporting), чтобы снизить нагрузку на DB в синхронных запросах.

---

## 15. Сжатие и хранение холодных данных

* Перекладывайте старые данные в отдельные таблицы/архивы.
* Используйте `pg_repack` или `VACUUM FULL` для уменьшения bloat.
* Используйте файловое хранилище (S3) для BLOB, храня в базе только метаданные.

---

## 16. Пример полного workflow оптимизации (практический)

1. Подключить `pg_stat_statements` → собрать топ-10 медленных запросов.
2. Для каждого: выполнять `EXPLAIN (ANALYZE, BUFFERS)` → понять bottleneck.
3. Если seq scan → добавить индекс / пересмотреть фильтр.
4. Если JOIN дорогой → убедиться что join-поля проиндексированы, или пересмотреть логику (batch).
5. Тусковые запросы → кэш/материализованные представления/переработка.
6. Запустить нагрузочные тесты, измерить p95/p99.
7. Настроить мониторинг и алерты на regressions.

---

## 17. Полезные SQL/ops команды и snippets

```sql
-- посмотреть наиболее bloated таблицы
SELECT relname, n_tup_ins, n_tup_upd, n_tup_del, n_dead_tup
FROM pg_stat_all_tables
ORDER BY n_dead_tup DESC
LIMIT 20;

-- посмотреть индексы по таблице
SELECT * FROM pg_indexes WHERE tablename = 'orders';

-- пересчитать статистику
ANALYZE VERBOSE orders;

-- очистка bloat (use with care)
VACUUM (VERBOSE, ANALYZE) orders;
```

---

## 18. Инструменты для автоматизации и анализа

* **pgBadger** — анализ логов
* **pganalyze**, **Percona Monitoring and Management (PMM)** — глубокий анализ
* **pg_repack** — уменьшение bloat без долгих блокировок
* **Citus** — шардинг (если нужна горизонтальная масштабируемость)

---

## 19. Контроль качества изменений (CI/PR)

* В pipeline перед deploy запускать:

  * `EXPLAIN` для новых SQL (проверка плана),
  * автоматические линтеры SQL (sqlfluff),
  * unit/integration тесты с локальной Postgres,
  * нагрузочные тесты для крупных изменений.

**Пример шага в GitLab CI:**

```yaml
stages:
  - test
  - analyze
  - deploy

analyze:
  script:
    - psql $DATABASE_URL -f migrations/001_create_orders.sql
    - psql $DATABASE_URL -c "EXPLAIN ANALYZE SELECT ...;"
```

---

## 20. Практические советы и anti-patterns

* **Не** индексируйте всё подряд (индексы замедляют writes).
* **Не** используйте `VACUUM FULL` на production без maintenance window.
* **Не** держите очень долгие транзакции.
* **Не** полагайтесь на ORM по умолчанию для сложных запросов — используйте raw SQL там, где нужна производительность.
* **Используйте** monitoring + alerts до и после каждой оптимизации.

---
